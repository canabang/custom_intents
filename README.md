# ğŸ¤– Assistant Vocal K-2SO : Hub Central

Qui n'a pas rÃªvÃ© de commander sa maison Ã  la voix, avec ses propres mots et expressions ? 
Baignant dans l'univers geek depuis toujours et fan inconditionnel de Star Trek, Star Wars, Stargate, Le Seigneur des Anneaux ou encore Doctor Who, mon but Ã©tait simple : rendre ma maison aussi interactive que le pont de l'Enterprise ou la bibliothÃ¨que de Poudlard.

Pouvoir dire Â« Lumos Â» pour Ã©clairer une piÃ¨ce ou transformer son salon en Â« mode bunker Â» n'est plus de la science-fiction. Ã€ travers ces diffÃ©rentes phases, je vous invite Ã  suivre mon aventure dans la crÃ©ation d'un assistant vocal vraiment personnel, intelligent et avec du caractÃ¨re.

## ğŸ—ï¸ Architecture du SystÃ¨me

Voici comment les donnÃ©es circulent entre votre voix et vos appareils :

```mermaid
graph TD
    A["ğŸ¤ Voix (Utilisateur)"] -->|Commande| B["ğŸ›°ï¸ Satellites ESPHome"]
    B["ğŸ›°ï¸ Satellites ESPHome"] -->|Audio| C["ğŸ  HA Assist / Speech-to-Phrase"]
    C -->|Texte| D{"ğŸ¯ Matcher d'Intents"}
    D -->|PiÃ¨ce DÃ©tectÃ©e| E["ğŸ§  Template : Satellite MÃ©morisÃ©"]
    E -->|Contexte| F["ğŸ“œ Intent Scripts"]
    F -->|Action| G["ğŸ’¡ Appareils / LumiÃ¨res / Volets"]
    F -->|Demande IA| I["ğŸ¤– Ollama / Llama 3.2 (Local)"]
    I -->|RÃ©ponse Sarcastique| F
    F -->|Notification Vocale| H["ğŸ”Š Alexa / Amazon Echo"]
```

> [!TIP]
> **Architecture Hybride** : Ce projet utilise une Ã©coute 100% locale (ESP32) pour la fiabilitÃ©, mais peut utiliser le Cloud (Alexa) pour la sortie audio haute qualitÃ©. 
> [En savoir plus sur l'Architecture Vocale](./docs/architecture_vocale.md)

## ğŸ—ºï¸ La Route vers l'Automatisation Totale

### ğŸ“– Concepts Fondamentaux
Avant de commencer, il est crucial de comprendre les piliers du projet :
- **[Conventions de Nommage](./docs/conventions_nommage.md)** : La rÃ¨gle d'or pour que le contexte fonctionne.
- **[Architecture Vocale](./docs/architecture_vocale.md)** : Pourquoi le local est roi.

---

| Phase | Nom | Focus | FonctionnalitÃ© ClÃ© |
| :--- | :--- | :--- | :--- |
| **Phase 1** | [Validation Technique](./phase_1/) | FiabilitÃ© | Allumage direct et validation du flux. |
| **Phase 2** | [ModularitÃ© & Contexte](./phase_2/) | PiÃ¨ces | DÃ©tection automatique de la piÃ¨ce (LumiÃ¨res & Volets). |
| **Phase 2.1** | [Intelligence AvancÃ©e](./phase_2.1/) | ScÃ¨nes | Choix automatique des scÃ¨nes (Jour/Nuit/Veilleuse). |
| **Phase 2.2** | [IA & PersonnalitÃ©](./phase_2.2/) | **CaractÃ¨re** | **IntÃ©gration Ollama & Humour K-2SO (100% Local).** |

---

### ğŸ§ª [Phase 1 : Validation Technique Directe](./phase_1/)
**Objectif** : Valider le flux "Voix â†’ Home Assistant" le plus vite possible.
- **Pourquoi la suivre ?** Pour Ãªtre sÃ»r que votre matÃ©riel est bien synchronisÃ©.

### ğŸ§­ [Phase 2 : ModularitÃ© & Contexte](./phase_2/)
**Objectif** : Rendre la maison consciente de votre position.
- **Pourquoi la suivre ?** Pour ne plus jamais avoir Ã  nommer les piÃ¨ces.

### ğŸ§  [Phase 2.1 : Intelligence d'Ã‰clairage](./phase_2.1/)
**Objectif** : Gestion dynamique et scÃ¨nes intelligentes.
- **Technique** : IntÃ©gration du script `gerer_eclairage`.

### ğŸ¤– [Phase 2.2 : PersonnalitÃ© K-2SO (IA Locale)](./phase_2.2/)
**Objectif** : Ajouter un caractÃ¨re sarcastique Ã  chaque interaction vocale.
- **Pourquoi la suivre ?** Pour transformer un simple robot en un assistant (pÃ©niblement) humain.
- **Technique** : Utilisation d'**Ollama** (Llama 3.2) hÃ©bergÃ© dans un **conteneur Docker sur un NAS Open Media Vault (OMV)**.
- **Performance** : Utilisation du Passthrough GPU (GTX 1050 Ti) pour une confidentialitÃ© totale et un fonctionnement offline.

---

## ğŸ› ï¸ Configuration MatÃ©rielle
Ce projet a Ã©tÃ© dÃ©veloppÃ© et testÃ© avec les Ã©quipements suivants :
-  **Serveur Domotique** : Mini-PC (CPU Intel N150, 16 Go de RAM) sous Home Assistant OS.
-  **Serveur IA & Docker** : NAS sous **Open Media Vault (OMV)**.
-  **GPU IA** : NVIDIA GTX 1050 Ti 4GB (Passthrough Docker).
-  **Satellites de Zone** :
    - Salon : **ESP32-Box S3** (ESPHome).
    - Chambre : **ReSpeaker Kit** (ESPHome).
    - Autres : 2 x Atom Echo (ESPHome).
-  **Sortie Audio** : Amazon Echo (Studio D, Show Cuisine/Chambre, SdB).

---

## ğŸ’» PrÃ©-requis Logiciels
Pour faire fonctionner ce projet, vous avez besoin de :
- **[Home Assistant](https://www.home-assistant.io/)** (Core ou OS).
- **[Speech-to-Phrase](https://github.com/OHF-voice/speech-to-phrase)** : Moteur de reconnaissance locale (STT).
- **[ESPHome](https://esphome.io/)** : Gestion des satellites (ESP32-Box, Atom Echo, etc.).
- **[Alexa Media Player](https://github.com/alandtse/alexa_media_player)** : IntÃ©gration pour la sortie audio.
- **[Ollama](https://www.home-assistant.io/integrations/ollama)** (ou **[Gemini](https://www.home-assistant.io/integrations/gemini)**) : Moteur d'IA conversationnelle.
- **[Piper](https://github.com/OHF-Voice/piper1-gpl)** : Add-on TTS local (optionnel si usage Alexa).

---

## ğŸš€ Comment dÃ©marrer ?

1.  **Exploration** : Lisez le README de la [Phase 1](./phase_1/README.md).
2.  **PrÃ©paration** : PrÃ©parez vos propres `entity_id` (Cibles & Satellites).
3.  **DÃ©ploiement** : Suivez les instructions "Express" dans l'ordre (1 -> 2 -> 2.1 -> 2.2).

> [!CAUTION]
> **Adaptation obligatoire** : Vous DEVEZ remplacer les identifiants d'entitÃ©s par les vÃ´tres pour que le systÃ¨me soit opÃ©rationnel.

---
*Projet dÃ©veloppÃ© pour une immersion totale. La Phase 2.2 (IA K-2SO) est la derniÃ¨re Ã©tape actuelle et fonctionne Ã  100% en local !* ğŸ¤–ğŸš€
